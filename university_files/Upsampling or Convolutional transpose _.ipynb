{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaafe793",
   "metadata": {},
   "source": [
    "# What should I use for upsampling ?\n",
    "\n",
    "In Keras, *Conv3D* and *Conv3DTranspose* are two different types of layers that can be used in a convolutional neural network.\n",
    "\n",
    "Conv3D is a 3D convolutional layer that performs a convolution operation on the input volume using a set of learnable filters. The output of a Conv3D layer has the same spatial dimensions as the input, but the depth (i.e., number of channels) may be different.\n",
    "\n",
    "On the other hand, Conv3DTranspose is a 3D transposed convolutional layer that performs an operation similar to \"deconvolution\". It takes the input with a smaller spatial resolution and a larger number of channels and applies a learnable upsampling process to increase the spatial dimensions while decreasing the depth (i.e., number of channels). Conv3DTranspose can be used for upsampling feature maps or generating high-resolution images from a low-resolution input.\n",
    "\n",
    "In other words, Conv3D is used for downsampling (or feature extraction), while Conv3DTranspose is used for upsampling (or feature map reconstruction).\n",
    "\n",
    "Let's see a 2D example, with keras Conv2DTranspose layer, that makes no real prediction but explains a lot ! To demonstrate how the Conv2DTranspose layer works let's start by creating a simple 2D image and passing it through a Conv2DTranspose layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_ticks(ax, nticks):\n",
    "    ax = plt.gca();\n",
    "\n",
    "    # Major ticks\n",
    "    ax.set_xticks(np.arange(0, nticks, 1))\n",
    "    ax.set_yticks(np.arange(0, nticks, 1))\n",
    "\n",
    "    # Labels for major ticks\n",
    "    ax.set_xticklabels(np.arange(1, nticks+1, 1))\n",
    "    ax.set_yticklabels(np.arange(1, nticks+1, 1))\n",
    "\n",
    "    # Minor ticks\n",
    "    ax.set_xticks(np.arange(-.5, nticks, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, nticks, 1), minor=True)\n",
    "\n",
    "    # Gridlines based on minor ticks\n",
    "    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n",
    "\n",
    "    # Remove minor ticks\n",
    "    ax.tick_params(which='minor', bottom=False, left=False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c68f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create a simple 2D image\n",
    "image = np.zeros((8, 8))\n",
    "image[2:6, 2:6] = 1\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "ax = plt.gca();\n",
    "ax = grid_ticks(ax,8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Define a transposed convolutional layer\n",
    "model = Sequential()\n",
    "model.add(Conv2DTranspose(1, kernel_size=3, strides=2, \n",
    "                          padding='same', input_shape=(8, 8, 1),\n",
    "                          kernel_initializer='ones'))\n",
    "\n",
    "# Apply the transposed convolution to the image\n",
    "image = image.reshape((1, 8, 8, 1))\n",
    "output = model.predict(image)\n",
    "output = output.reshape((16, 16))\n",
    "plt.imshow(output, cmap='gray')\n",
    "\n",
    "ax = plt.gca();\n",
    "ax = grid_ticks(ax,16)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48f476b",
   "metadata": {},
   "source": [
    "Can you see the deconvolution pattern ?\n",
    "\n",
    "### kernel initialisation\n",
    "\n",
    "Another interesting feature of the code we have just seen is that the kernel is initialised to 1, are there other ways to initialise the kernel values ?\n",
    "\n",
    "In Keras, you can initialize a layer by passing an initializer to the kernel_initializer or bias_initializer argument when creating the layer. Keras provides several built-in initializers, including:\n",
    "\n",
    "- zeros: Initializes weights or biases to all zeros\n",
    "- ones: Initializes weights or biases to all ones\n",
    "- constant: Initializes weights or biases to a constant value\n",
    "- random_normal: Initializes weights or biases with random values drawn from a normal distribution\n",
    "- random_uniform: Initializes weights or biases with random values drawn from a uniform distribution\n",
    "- glorot_normal or glorot_uniform: Initializes weights with random values drawn from a uniform or normal distribution, with the standard deviation scaled based on the number of input and output units.\n",
    "\n",
    "For example, to create a Dense layer with weights initialized to random values drawn from a normal distribution with mean 0 and standard deviation 0.01, you can use the following code:\n",
    "\n",
    "```\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "dense_layer = Dense(units=64, kernel_initializer=RandomNormal(mean=0.0, stddev=0.01))\n",
    "```\n",
    "\n",
    "You can also create a custom initializer by subclassing the keras.initializers.Initializer class and implementing its **__call__** method. Here's an example of a custom initializer that initializes weights with random values drawn from a truncated normal distribution with mean 0 and standard deviation 0.01:\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "from keras.initializers import Initializer\n",
    "\n",
    "class TruncatedNormal(Initializer):\n",
    "    def __init__(self, mean=0.0, stddev=0.01):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return tf.truncated_normal(shape, mean=self.mean, stddev=self.stddev)\n",
    "\n",
    "```\n",
    "\n",
    "You can then use this initializer in the same way as the built-in initializers:\n",
    "\n",
    "```\n",
    "dense_layer = Dense(units=64, kernel_initializer=TruncatedNormal(mean=0.0, stddev=0.01))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d17ea",
   "metadata": {},
   "source": [
    "# Upsampling\n",
    "\n",
    "Instead of a convolutional transpose layer, you may want to use the upsampling layer (similar to the pooling layer). The Upsampling layer in Keras is used to increase the spatial dimensions (width and height) of the input feature maps. It is often used in combination with a previous pooling layer to restore the original spatial resolution of the input feature maps.\n",
    "\n",
    "The Upsampling layer essentially repeats each pixel value in the input feature maps a certain number of times to increase the spatial resolution. There are two main types of upsampling layers in Keras: `UpSampling2D` and `UpSampling3D`. `UpSampling2D` is used for 2D images, while `UpSampling3D` is used for 3D volumetric data.\n",
    "\n",
    "The `UpSampling2D` layer takes as input a tensor of shape `(batch_size, height, width, channels)`, where `batch_size` is the number of samples in a batch, `height` and `width` are the spatial dimensions of the input feature maps, and `channels` is the number of channels in the input feature maps. The layer outputs a tensor of shape `(batch_size, height * size_factor, width * size_factor, channels)`, where `size_factor` is the upsampling factor, which is a positive integer that specifies how much to increase the spatial dimensions.\n",
    "\n",
    "The `UpSampling3D` layer takes as input a tensor of shape `(batch_size, depth, height, width, channels)`, where `batch_size` is the number of samples in a batch, `depth`, `height`, and `width` are the spatial dimensions of the input feature maps, and `channels` is the number of channels in the input feature maps. The layer outputs a tensor of shape `(batch_size, depth * size_factor, height * size_factor, width * size_factor, channels)`, where `size_factor` is the upsampling factor, which is a positive integer that specifies how much to increase the spatial dimensions.\n",
    "\n",
    "The `UpSampling2D` and `UpSampling3D` layers use a nearest neighbor algorithm to perform the upsampling. Specifically, each pixel value in the input feature maps is repeated size_factor times in each spatial dimension to produce the output feature maps.\n",
    "\n",
    "It's important to note that the Upsampling layer does not learn any parameters. It simply repeats the pixel values in the input feature maps to increase the spatial resolution. If you need to learn the upsampling, you can use the `Conv2DTranspose` or `Conv3DTranspose` layers, which learn to upsample the feature maps using trainable parameters.\n",
    "\n",
    "Let's see what happens when using UpSampling2D layer instead of Conv2DTranspose to upsample a 2D image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd572af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import UpSampling2D\n",
    "\n",
    "# Create a simple 2D image\n",
    "image = np.zeros((8, 8))\n",
    "image[2:6, 2:6] = 1\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "ax = plt.gca();\n",
    "ax = grid_ticks(ax,8)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Define an upsampling layer\n",
    "model = Sequential()\n",
    "model.add(UpSampling2D(size=(2, 2), input_shape=(8, 8, 1)))\n",
    "\n",
    "# Apply the upsampling to the image\n",
    "image = image.reshape((1, 8, 8, 1))\n",
    "output = model.predict(image)\n",
    "output = output.reshape((16, 16))\n",
    "plt.imshow(output, cmap='gray')\n",
    "\n",
    "ax = plt.gca();\n",
    "ax = grid_ticks(ax,16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fedb4",
   "metadata": {},
   "source": [
    "In this example, we create the same 2D image as before and plot it using matplotlib.\n",
    "\n",
    "Next, we define a Keras model with an UpSampling2D layer. This layer has a size of (2, 2), which doubles the dimensions of the input image in both dimensions. We also specify the input shape of the layer to match the shape of our input image.\n",
    "\n",
    "We then reshape the input image to have a batch size of 1 and pass it through the UpSampling2D layer using the predict method. Finally, we reshape the output of the layer to be a 16x16 image and plot it using matplotlib.\n",
    "\n",
    "The UpSampling2D layer performs an upsampling operation on the input image. In this example, the size of (2, 2) causes the output image to be twice as large in both dimensions as the input image.\n",
    "\n",
    "Note that like Conv2DTranspose, UpSampling2D is often used in conjunction with other layers, such as convolutional and pooling layers, in deep learning models for image generation and inpainting. This example demonstrates the basic usage of the layer for upsampling purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
